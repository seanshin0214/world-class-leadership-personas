"""Persona RAG MCP Server - RAG ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ ì§€ì‹ ê²€ìƒ‰"""
import os
import sys
from pathlib import Path
from typing import Optional

# Windows stdout/stderr UTF-8 ì„¤ì •
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

from mcp.server import Server
from mcp.server.stdio import stdio_server
from mcp.types import Tool, TextContent

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from vector_store import PersonaVectorStore


# ë²¡í„° ìŠ¤í† ì–´ - ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™”
DATA_DIR = Path(__file__).parent / "data" / "chroma_db"

import threading
_vector_store = None
_init_lock = threading.Lock()
_init_done = threading.Event()

def _background_init():
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ëª¨ë¸ ë¡œë”©"""
    global _vector_store
    _vector_store = PersonaVectorStore(str(DATA_DIR))
    _ = _vector_store.encoder  # SentenceTransformer ë¡œë“œ
    _init_done.set()
    print("ë²¡í„° ìŠ¤í† ì–´ ì¤€ë¹„ ì™„ë£Œ", file=sys.stderr)

# ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ì¦‰ì‹œ ì‹œì‘
threading.Thread(target=_background_init, daemon=True).start()

def get_vector_store():
    """ë²¡í„° ìŠ¤í† ì–´ ë°˜í™˜ (ì´ˆê¸°í™” ì™„ë£Œ ëŒ€ê¸°)"""
    _init_done.wait()
    return _vector_store


# MCP ì„œë²„ ìƒì„±
server = Server("persona-rag")


@server.list_tools()
async def list_tools():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ë°˜í™˜"""
    return [
        Tool(
            name="search_persona_knowledge",
            description="""142ê°œ ì›”ë“œí´ë˜ìŠ¤+ í˜ë¥´ì†Œë‚˜ì˜ ì „ë¬¸ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

í¬í•¨ëœ ì§€ì‹:
- ê°œë°œ: Software Engineer, Backend, Frontend, DevOps, Security, QA ë“±
- ë””ìì¸: UX/UI Designer, Graphic Designer, Animator ë“±
- ë¹„ì¦ˆë‹ˆìŠ¤: CEO, CTO, CFO, Product Manager, Sales ë“±
- AI/ML: Data Scientist, ML Engineer, LLM Engineer, AI Researcher ë“±
- êµìœ¡: Professor, Teacher, Curriculum Developer ë“±
- ì˜ë£Œ: Physician, Nurse, Pharmacist, Psychologist ë“±

ì‚¬ìš© ì˜ˆì‹œ:
- "FastAPIì—ì„œ ì¸ì¦ êµ¬í˜„ ë°©ë²•"
- "UX ë””ìì¸ ì›ì¹™"
- "ìŠ¤íƒ€íŠ¸ì—… ìê¸ˆ ì¡°ë‹¬ ì „ëµ"
- "LLM íŒŒì¸íŠœë‹ ë°©ë²•"
            """,
            inputSchema={
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "ê²€ìƒ‰í•  ì§ˆë¬¸ ë˜ëŠ” ì£¼ì œ"
                    },
                    "n_results": {
                        "type": "integer",
                        "description": "ë°˜í™˜í•  ê²°ê³¼ ìˆ˜ (ê¸°ë³¸: 5)",
                        "default": 5
                    }
                },
                "required": ["query"]
            }
        ),
        Tool(
            name="search_by_persona",
            description="""íŠ¹ì • í˜ë¥´ì†Œë‚˜ì˜ ì „ë¬¸ ì§€ì‹ë§Œ ê²€ìƒ‰í•©ë‹ˆë‹¤.

í˜ë¥´ì†Œë‚˜ ID ì˜ˆì‹œ:
- 101-software-engineer, 102-backend-engineer
- 201-ui-ux-designer, 222-graphic-designer
- 327-cto, 329-ceo, 330-product-manager
- 401-data-scientist, 410-llm-engineer
- 602-professor, 701-physician

ì „ì²´ ëª©ë¡ì€ list_personas ë„êµ¬ë¡œ í™•ì¸í•˜ì„¸ìš”.
            """,
            inputSchema={
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "ê²€ìƒ‰í•  ì§ˆë¬¸"
                    },
                    "persona_id": {
                        "type": "string",
                        "description": "í˜ë¥´ì†Œë‚˜ ID (ì˜ˆ: 410-llm-engineer)"
                    },
                    "n_results": {
                        "type": "integer",
                        "description": "ë°˜í™˜í•  ê²°ê³¼ ìˆ˜ (ê¸°ë³¸: 5)",
                        "default": 5
                    }
                },
                "required": ["query", "persona_id"]
            }
        ),
        Tool(
            name="list_personas",
            description="RAG ì§€ì‹ ë² ì´ìŠ¤ì— ë“±ë¡ëœ ëª¨ë“  í˜ë¥´ì†Œë‚˜ ëª©ë¡ì„ í‘œì‹œí•©ë‹ˆë‹¤.",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        ),
        Tool(
            name="get_persona_stats",
            description="í˜ë¥´ì†Œë‚˜ RAG ë²¡í„° ìŠ¤í† ì–´ì˜ í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        )
    ]


@server.call_tool()
async def call_tool(name: str, arguments: dict):
    """ë„êµ¬ ì‹¤í–‰"""

    if name == "search_persona_knowledge":
        query = arguments.get("query", "")
        n_results = arguments.get("n_results", 5)

        results = get_vector_store().search(query, n_results=n_results)

        if not results:
            return [TextContent(
                type="text",
                text=f"'{query}'ì— ëŒ€í•œ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )]

        output = f"## ğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼\n\n"
        for i, r in enumerate(results, 1):
            persona_name = r["metadata"].get("persona_name", "Unknown")
            persona_id = r["metadata"].get("persona_id", "")
            output += f"### [{i}] {persona_name} ({persona_id})\n"
            output += f"**ê´€ë ¨ë„**: {1 - r['distance']:.2%}\n\n"
            output += f"{r['content']}\n\n"
            output += "---\n\n"

        return [TextContent(type="text", text=output)]

    elif name == "search_by_persona":
        query = arguments.get("query", "")
        persona_id = arguments.get("persona_id", "")
        n_results = arguments.get("n_results", 5)

        results = get_vector_store().search_by_persona(query, persona_id, n_results=n_results)

        if not results:
            return [TextContent(
                type="text",
                text=f"'{persona_id}'ì˜ '{query}'ì— ëŒ€í•œ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                     f"ì‚¬ìš© ê°€ëŠ¥í•œ í˜ë¥´ì†Œë‚˜: list_personas ë„êµ¬ë¡œ í™•ì¸í•˜ì„¸ìš”."
            )]

        persona_name = results[0]["metadata"].get("persona_name", persona_id)
        output = f"## ğŸ¯ [{persona_name}] '{query}' ê²€ìƒ‰ ê²°ê³¼\n\n"
        for i, r in enumerate(results, 1):
            output += f"### [{i}] ê´€ë ¨ë„: {1 - r['distance']:.2%}\n\n"
            output += f"{r['content']}\n\n"
            output += "---\n\n"

        return [TextContent(type="text", text=output)]

    elif name == "list_personas":
        personas = get_vector_store().get_all_personas()

        if not personas:
            return [TextContent(
                type="text",
                text="ë“±ë¡ëœ í˜ë¥´ì†Œë‚˜ê°€ ì—†ìŠµë‹ˆë‹¤. data_loader.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”."
            )]

        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
        categories = {
            "1xx - Engineering": [],
            "2xx - Design & Creative": [],
            "3xx - Business & Leadership": [],
            "4xx - AI & Data Science": [],
            "5xx - Testing & QA": [],
            "6xx - Education": [],
            "7xx - Healthcare": [],
            "8xx - Other": []
        }

        for p in personas:
            try:
                num = int(p.split('-')[0])
                if 100 <= num < 200:
                    categories["1xx - Engineering"].append(p)
                elif 200 <= num < 300:
                    categories["2xx - Design & Creative"].append(p)
                elif 300 <= num < 400:
                    categories["3xx - Business & Leadership"].append(p)
                elif 400 <= num < 500:
                    categories["4xx - AI & Data Science"].append(p)
                elif 500 <= num < 600:
                    categories["5xx - Testing & QA"].append(p)
                elif 600 <= num < 700:
                    categories["6xx - Education"].append(p)
                elif 700 <= num < 800:
                    categories["7xx - Healthcare"].append(p)
                else:
                    categories["8xx - Other"].append(p)
            except:
                categories["8xx - Other"].append(p)

        output = "## ğŸ‘¥ Persona RAG ì§€ì‹ ë² ì´ìŠ¤\n\n"
        for cat, items in categories.items():
            if items:
                output += f"### {cat}\n"
                for p in items:
                    output += f"- `{p}`\n"
                output += "\n"

        output += f"\n**ì´ í˜ë¥´ì†Œë‚˜ ìˆ˜**: {len(personas)}"

        return [TextContent(type="text", text=output)]

    elif name == "get_persona_stats":
        doc_count = get_vector_store().get_document_count()
        personas = get_vector_store().get_all_personas()

        output = "## ğŸ“Š Persona RAG í†µê³„\n\n"
        output += f"- **ì´ ë¬¸ì„œ ì²­í¬ ìˆ˜**: {doc_count}\n"
        output += f"- **ë“±ë¡ëœ í˜ë¥´ì†Œë‚˜ ìˆ˜**: {len(personas)}\n"

        return [TextContent(type="text", text=output)]

    else:
        return [TextContent(
            type="text",
            text=f"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {name}"
        )]


async def main():
    """MCP ì„œë²„ ì‹¤í–‰"""
    async with stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            server.create_initialization_options()
        )


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
